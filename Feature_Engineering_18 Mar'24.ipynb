{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad763330-a918-45db-81fd-4a1eb4e92195",
   "metadata": {},
   "source": [
    "## Q1. What is the Filter method in feature selection, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab89e86-6f68-4580-9f59-34dc10ecbe4c",
   "metadata": {},
   "source": [
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790255b-d650-4665-af32-a7e9cb38fc10",
   "metadata": {},
   "source": [
    "### filter method in Feature Selection involves choosing top ranked features or most important features for the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a214f5-a0e2-4b37-8da2-b7e01bcd7247",
   "metadata": {},
   "source": [
    "## Why is it important ? :\n",
    "### Simplifies the model: Reduces data storage, follows Occam’s razor, and improves visualization.\n",
    "### Reduces training time.\n",
    "### Avoids overfitting.\n",
    "### Improves model accuracy.\n",
    "### Helps avoid the curse of dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb429933-7fd8-4268-af6b-0e214fe28b5d",
   "metadata": {},
   "source": [
    "## How does it works ? :\n",
    "#### Calculate a metric (e.g., correlation) for each feature with respect to the dependent variable.\n",
    "#### Rank features based on this metric.\n",
    "#### Select the top-ranked features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db644786-1c7e-42bd-80fa-34e46cc36c9e",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4434c-4538-4502-958c-0e423facb746",
   "metadata": {},
   "source": [
    "## Q2. How does the Wrapper method differ from the Filter method in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314efc45-6672-43bf-9f62-58d5e14aeefa",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635144fc-4e2e-49a6-a265-20ad0ca2f29c",
   "metadata": {},
   "source": [
    "### Wrapper Method: Like trying on different outfits (feature subsets) to see which one fits the best (model performance). It’s specific to the model you’re using.\n",
    "### Filter Method: Like sorting features based on their individual qualities (e.g., color, fabric) without trying them on. It ranks features independently of any specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f8429-8229-4a69-8db1-871c1d9b998b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de34eeb-49a9-45fa-9cb5-f069d2a71eb7",
   "metadata": {},
   "source": [
    "## Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42a344-683e-4c8d-8f3b-4b63ee53263e",
   "metadata": {},
   "source": [
    "#### Lasso (Least Absolute Shrinkage and Selection Operator): Lasso uses L1 regularization to encourage some regression coefficients to shrink to zero, effectively performing feature selection.\n",
    "#### Feature Importance from Decision Trees: Decision trees provide a natural way to assess feature importance, ranking features based on their impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72af2ef9-82ba-480c-be6e-b98b2bb30b8a",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81349b3-f0a8-460b-a714-62e804bc0254",
   "metadata": {},
   "source": [
    "## Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3adf1-05a2-4598-96e6-b947f05875e7",
   "metadata": {},
   "source": [
    "### Rigidity and Ignorance:\n",
    "#### Filter methods are fixed and do not adapt to the model. They evaluate features individually, ignoring interactions between features and the model.\n",
    "#### They may miss important feature combinations that affect predictive performance.\n",
    "### Lack of Multivariate Consideration:\n",
    "#### Filter methods rank features independently (univariate). As a result, they don’t necessarily eliminate redundant variables.\n",
    "#### Multivariate filter methods exist but are less common1.\n",
    "### Limited Interaction Awareness:\n",
    "#### These methods don’t capture complex interactions between features\n",
    "#### For instance, they might miss synergistic effects where two features together provide more information than each separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e896064-e7d5-4b86-896e-574416815da8",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e92bc-8e01-4f19-b7db-ed02224c7fbf",
   "metadata": {},
   "source": [
    "## Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804b5bd-0edd-4068-8648-d6c358a1ad25",
   "metadata": {},
   "source": [
    "### High-Dimensional Data:\n",
    "#### When dealing with a large number of features, filter methods are computationally efficient. They evaluate features independently and don’t require training a model for each feature subset.\n",
    "### Preprocessing and Data Cleaning:\n",
    "#### Filter methods are useful for removing irrelevant, duplicated, or highly correlated features during data preprocessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252ecdc-7e05-4265-b6dd-52da5d367184",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2579dd-6b00-4aa0-8ff3-1e89c6692018",
   "metadata": {},
   "source": [
    "## Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725220c-e2fe-4580-8e9b-3d764d07182d",
   "metadata": {},
   "source": [
    "### Data Preparation: First, ensure your dataset is clean and well-organized. Handle missing values, outliers, and any other data quality issues. \n",
    "##\n",
    "### Feature Ranking:\n",
    "#### Calculate a relevance score for each feature. Common methods include:\n",
    "#### Correlation: Measure the linear relationship between each feature and the target variable (churn rate in this case). Features with higher absolute correlation values are more relevant.\n",
    "#### Mutual Information: Assess the dependency between features and the target. Higher mutual information indicates stronger relevance.\n",
    "#### Chi-Square Test: Useful for categorical features.\n",
    "#### ANOVA F-test: For continuous features.\n",
    "##\n",
    "### Model Building:\n",
    "#### Train your predictive model using the selected features.\n",
    "#### Evaluate its performance on the validation set.\n",
    "#### Common algorithms include logistic regression, decision trees, or random forests.\n",
    "##\n",
    "### Iterate and Refine:\n",
    "#### If the model performs well, great! If not, consider:\n",
    "#### Adding or removing features based on domain knowledge.\n",
    "#### Trying different thresholds for feature selection.\n",
    "#### Exploring interactions between features.\n",
    "#### Regularization techniques (e.g., L1 or L2 regularization) to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf11e19-4c1d-456b-abd3-f7a7591fae02",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca65958-b141-4f89-a128-0df2b2f0bdea",
   "metadata": {},
   "source": [
    "## Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. Explain how you would use the Embedded method to select the most relevant features for the model.\n",
    "## Answer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82fd684-b544-4ab4-95f8-81dcb9498f41",
   "metadata": {},
   "source": [
    "### Choose a Model with Built-in Feature Selection:\n",
    "#### Lasso Regression (L1 Regularization): Penalizes coefficients, effectively shrinking some to zero. Non-zero coefficients correspond to relevant features.\n",
    "#### Elastic Net: Combines L1 and L2 regularization.\n",
    "#### Random Forests: Feature importance scores are calculated during tree construction.\n",
    "#### Gradient Boosting (e.g., XGBoost, LightGBM): Feature importance is learned during boosting iterations.\n",
    "## \n",
    "### Feature Importance or Coefficient Magnitude:\n",
    "#### Train your chosen model on the dataset.\n",
    "##\n",
    "### Threshold Selection:\n",
    "#### Set a threshold for feature selection. You can choose a fixed number of top features (e.g., top 10) or a percentage (e.g., top 20%).\n",
    "#### Keep the features that meet or exceed the threshold.\n",
    "##\n",
    "### Model Evaluation and Refinement:\n",
    "#### Evaluate your model’s performance using cross-validation or a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334e608-334d-4d5b-8bf2-13db7e398bcc",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86024b9d-cdb5-482c-811d-22d8d1a0a16d",
   "metadata": {},
   "source": [
    "## Q8. You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. Explain how you would use the Wrapper method to select the best set of features for the predictor.\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94dd9c-e4f9-4716-9223-4708804004f9",
   "metadata": {},
   "source": [
    "### Stepwise Feature Selection:\n",
    "#### There are two common approaches:\n",
    "#### Forward Selection:\n",
    "#### Begin with an empty set of features.\n",
    "#### Add the feature that improves model performance the most (e.g., reduces error or increases R-squared).\n",
    "#### Continue adding features until performance no longer improves significantly.\n",
    "### Backward Elimination:\n",
    "#### Start with all feature\n",
    "#### Remove the feature that has the least impact on performance.\n",
    "#### Repeat until further removals degrade performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c6bbb-5f15-4c76-baf8-63b30e2fc164",
   "metadata": {},
   "source": [
    "### Model Evaluation:\n",
    "#### At each step, train your model using the selected features.\n",
    "#### Evaluate its performance using cross-validation or a validation set.\n",
    "##\n",
    "### topping Criteria:\n",
    "#### Decide when to stop adding or removing features:\n",
    "#### Use a threshold (e.g., p-value, performance improvement).\n",
    "#### Set a maximum number of features.\n",
    "##\n",
    "### Regularization Techniques:\n",
    "#### Consider using regularization methods (e.g., Ridge, Lasso) during model training\n",
    "#### These techniques penalize certain features, encouraging sparsity and preventing overfitting.\n",
    "##\n",
    "### Iterate and Validate:\n",
    "#### Repeat the process, exploring different feature combinations.\n",
    "#### Validate the final model on an independent test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
