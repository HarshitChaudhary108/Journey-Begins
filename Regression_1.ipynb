{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d075cbad-a043-43c5-94e7-c162c1df12cf",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab8797d-eb53-44e5-9745-06325ea479ea",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression :\n",
    "- Simple Linear Regression consist of 1 input or independent feature and 1 output feature\n",
    "- Formula : Hq(x) = Qo + Q1x1\n",
    "- E.g : We have given Weight and have to predict the Height.\n",
    "#### Multiple Linear Regression :\n",
    "- Multiple Linear Regression consist of more than 1 input or independent features and 1 output of dependent feature.\n",
    "- Formula : Hq(x) = Qo + Q1x1 + Q2x2 +........+Qnxn\n",
    "- E.g : We have given the No. of rooms, and the size of house and we we have to predict the price of house."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba6edea-61c1-4e72-a752-0aa26ac40c0d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f197e8d-d7f7-42c1-8c07-9b8f8e85efaf",
   "metadata": {},
   "source": [
    "##  Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f41ec73-2f0d-4224-ab3c-13576777dea1",
   "metadata": {},
   "source": [
    "#### Linearity: The relationship between the independent and dependent variables should be linear.\n",
    "- We can create a scatter plot of the independent variable (X) against the dependent variable (Y). If the points form a straight line, the linearity assumption is likely met.\n",
    "#### Normality: The residuals should be normally distributed.\n",
    "- We can create a Q-Q plot (quantile-quantile plot) of the residuals. If the points lie approximately along a straight line, the normality assumption is likely met.\n",
    "#### Independence: The residuals (errors) should be independent.\r",
    "- We can uUse a Durbin-Watson test to detect any autocorrelation in the residuals. A value close to 2 indicates no autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8782787-ab06-4ef8-882f-d7496491d2b1",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f316b-320a-45c6-bb8c-9fb1f3f4ee84",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd4549-6364-4bc8-a1aa-ef39613e9358",
   "metadata": {},
   "source": [
    "### Let’s consider a real-world scenario: predicting the price of a house based on its size.\n",
    "#### Dependent Variable (Y): Price of the house (in thousands of dollars).\n",
    "#### Independent Variable (X): Size of the house (in square feet).\n",
    "###\n",
    "#### Suppose we have the following regression equation from our model:\n",
    "    - Price=50+0.2×Size\n",
    "#### Interpretation\n",
    "##### If a house is 1,000 square feet, the predicted price would be:\n",
    "##### Price=50+0.2×1000=50+200=250 (in thousands of dollars)\n",
    "    - So, the predicted price is $250,000.\n",
    "\n",
    "\n",
    "##### If a house is 1,500 square feet, the predicted price would be:\n",
    "##### Price=50+0.2×1500=50+300=350 (in thousands of dollars)\n",
    "    - So, the predicted price is $350,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f208a3e-dcac-47a3-a25f-92f8bd078c15",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d71820d-3e2f-4efd-8ae3-a4462c485799",
   "metadata": {},
   "source": [
    "#### We interpret the intercept and the slope, in order to get the best fit of line where the submission of errors = Null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3e92f-e25f-493d-a794-79dbe11d8fee",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adcea5-a5b1-4cc2-a437-db5b062824c2",
   "metadata": {},
   "source": [
    "##  Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798488e4-6eb8-40dd-83c1-30bdc6ab5713",
   "metadata": {},
   "source": [
    "#### Consider training a linear regression model to predict house prices based on size. The cost function could be the mean squared error between the predicted and actual prices. Gradient descent will iteratively adjust the weights (coefficients) and bias (intercept) to minimize this error, leading to an optimal model that accurately predicts house prices based on size.\n",
    "#### Gradient descent is a powerful tool that enables machine learning models to learn from data and improve their predictions by minimizing errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b74e4-9191-46e1-91d5-8d373bf08ccf",
   "metadata": {},
   "source": [
    "### Concept of Gradient Descent\n",
    "#### Gradient descent aims to find the optimal parameters (weights and biases) of a model by iteratively moving in the direction of the steepest decrease in the cost function. The cost function measures the difference between the predicted and actual values, and the goal is to minimize this difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1978864-a1b6-43b0-8426-4a7bf190d6f3",
   "metadata": {},
   "source": [
    "### How is it used in Machine Learning :\n",
    "#### In machine Learning, let say we have to make a simple linear regression model, the Gradient descent will helps us to create a model where the error is at lowest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e6143-05f3-4729-89f2-ed1c08d6eadb",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c569d6a4-c3e5-4d1d-a25d-9b142d6aeec4",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afdf4d6-875a-4a75-affe-58b223923e38",
   "metadata": {},
   "source": [
    "- Formula : Hq(x) = Qo + Q1x1 + Q2x2 +........+Qnxn\n",
    "- E.g : We have given the No. of rooms, and the size of house and we we have to predict the price of house.\n",
    "#### Unlike Linear Regression Model, In multiple Linear Regression Model we have more than 1 independent features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c8e5f-3764-4bec-bb24-c04d1cbce3a1",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc4d6c-4045-4715-aac4-fd34e5e602cc",
   "metadata": {},
   "source": [
    "##  Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f8710-c712-4a0e-9f82-2cb64e557212",
   "metadata": {},
   "source": [
    "#### Definition: It’s when two or more predictor variables in a regression model are very similar or correlated.\n",
    "#### Problem: This makes it hard to figure out the individual effect of each predictor on the outcome.\n",
    "### Detection of Multicollinearity :\n",
    "#### Variance Inflation Factor (VIF): This is a common method to detect multicollinearity. VIF measures how much the variance of a regression coefficient is inflated due to multicollinearity.\n",
    "#### Interpretation:\n",
    "- VIF = 1: No correlation between the predictor and other variables.\n",
    "- 1 < VIF < 5: Moderate correlation, usually acceptable.\n",
    "- VIF > 5: High correlation, problematic.\n",
    "### How to Solve/Address this issue :\n",
    "#### Remove One Predictor: If two predictors are very similar, you can remove one.\n",
    "#### Combine Predictors: Merge the similar predictors into one new variable.\n",
    "#### Ridge Regression: A special type of regression that can handle multicollinearity better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b14b2b-34ad-495b-8723-3a03e70076d0",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c804e5-8322-4c33-98ab-74fc6007e831",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc8217-1c44-433a-a9c9-f9913a23dfec",
   "metadata": {},
   "source": [
    "### Polynomial Regression Model :\n",
    "#### Polynomial regression is a type of regression analysis used when the relationship between the independent variable ( x ) and the dependent variable ( y ) is not linear.\n",
    "### Comparison with Linear Regression :\n",
    "#### Unlike simple linear regression model, In polynomial regression model the relationship between independent and dependent variable is not linear.\n",
    "#### Unlike simple linear regression model :\n",
    "- Hq(x) = Qo + Q1x1 + Q2(power 2)x3(power 2) + Q3(power 3)x3(power 3) + .................... + Qn(power n)xn(power n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643cd4b-71ed-4f43-a386-7a444d47d0ed",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6038ff7-bff3-45f7-a5c2-41d1feedd35d",
   "metadata": {},
   "source": [
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d45b2-d14e-48f9-a456-1079d49c6872",
   "metadata": {},
   "source": [
    "### Advantages :\n",
    "- Flexibility: Polynomial regression can model more complex, nonlinear relationships between the independent and dependent variables, which linear regression cannot.\n",
    "- Better Fit for Curved Data: When the data shows a curved pattern, polynomial regression can provide a better fit than a straight line.\n",
    "- Higher Accuracy: For datasets where the relationship is inherently nonlinear, polynomial regression can yield more accurate predictions.\n",
    "### Disadvantages :\n",
    "- Overfitting: Higher-degree polynomials can fit the training data very well but may perform poorly on new, unseen data. This is known as overfitting.\n",
    "- Complexity: Polynomial models are more complex and harder to interpret compared to linear models.\n",
    "- Computationally Intensive: Higher-degree polynomials require more computational resources and can be more challenging to optimize.\n",
    "### WHEN TO USE :\n",
    "- Nonlinear Relationships: When the relationship between the independent and dependent variables is not linear and shows a curved pattern.\r",
    "- \n",
    "Visual Inspection: If a scatterplot of the data suggests a curved relationship, polynomial regression might be more appropriate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
