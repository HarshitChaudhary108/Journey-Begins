{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cec27ed-7da1-4bc5-83eb-cac338ecdfc7",
   "metadata": {},
   "source": [
    "## Q1. What is the KNN algorithm?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d17bc-650b-4ff0-aacd-e8aab7a97f4f",
   "metadata": {},
   "source": [
    "### The K-Nearest Neighbors (KNN) algorithm is one of the simplest and most intuitive tools in machine learning, Think of it like making predictions by asking a group of friends who live close to you: ‚ÄúHey, what do you think this is?‚Äù\n",
    "- When given a new data point, it looks at the ‚Äòk‚Äô closest neighbors (based on distance) and predicts the label based on majority vote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78e214-79dc-4032-90f1-f31f9560e296",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b80e2e-df36-4b1b-9cb4-b3ec8eefc62a",
   "metadata": {},
   "source": [
    "## Q2. How do you choose the value of K in KNN?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca26606-54e0-4f32-8e59-c6dab71f0261",
   "metadata": {},
   "source": [
    "#### Choosing the right value of K in K-Nearest Neighbors is like finding the right number of friends to ask for advice‚Äîtoo few, and your prediction might be biased; too many, and it could get diluted by noise.\n",
    "## 1. Try different K values and test which one gives the best performance on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00304fec-cb7c-4b86-a3f7-31b916256738",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ee81b-51d2-4195-bd66-1a0c52a19854",
   "metadata": {},
   "source": [
    "## Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31209fe7-4e63-400e-9548-7dd8d0634654",
   "metadata": {},
   "source": [
    "### Output :\n",
    "- Regressor : deals with numbers\n",
    "- Classifier : deals with labels (e.g : 0, 1)\n",
    "### Voting Method :\n",
    "- Regressor : Average of all\n",
    "- Classifier : majority votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c182d9-9d54-4e15-ae3b-b0daaf3b38b6",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e351c-8b0d-4e59-b8af-7b0ab0831f3e",
   "metadata": {},
   "source": [
    "## Q4. How do you measure the performance of KNN?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c09d8c9-551b-4509-abbc-94080348ab7b",
   "metadata": {},
   "source": [
    "#### For KNN Classifier :\n",
    "- Accuracy Score, Precision, Recall, F1 Score & Confusion Matrix\n",
    "#### For KNN Regressor :\n",
    "- MAE, MSE & R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31706a55-b22a-4d37-8b89-622f356f1bd6",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377658f1-8dc1-46d3-9d89-de047028e6d9",
   "metadata": {},
   "source": [
    "## Q5. What is the curse of dimensionality in KNN?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0802a9-0c11-4c4a-8d30-f0ffcffaa6c7",
   "metadata": {},
   "source": [
    "#### KNN relies on measuring distance to find the closest points. But:\n",
    "- When you have many dimensions, all distances tend to look similar.\n",
    "- Data becomes sparse, and density vanishes.\n",
    "- This makes KNN confused‚Äîit can't reliably say which points are truly similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056bf28-9ae8-4a2d-9ed0-ca47c5b2bb6c",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4940d-5aa3-4eda-b0cf-3e3bbcf65c78",
   "metadata": {},
   "source": [
    "## Q6. How do you handle missing values in KNN?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adf81c-8dde-4eab-918b-bb702eb62592",
   "metadata": {},
   "source": [
    "#### 1. Custom Imputation using \"fillna\".\n",
    "#### 2. Imputation using mean, Median & Mode using \"SimpleImputer\"\n",
    "#### 3. drop rows & Columns (If we can afford)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a338281-5db6-4e47-9298-b722beb7e112",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860cc83-c3d6-4b37-89f4-8940725a95b4",
   "metadata": {},
   "source": [
    "## Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d84b15-1366-4381-bcca-d720b58e2812",
   "metadata": {},
   "source": [
    "#### KNN Classifier\t\n",
    "- Predicts a class label (like \"yes\"/\"no\", 0/1)\n",
    "#### KNN Regressor\n",
    "- Predicts a numeric value (like 42.5)\n",
    "--------------------------------------------------------------------------------\n",
    "#### Use KNN Classifier: \n",
    "- if you're predicting categories like \"High Engagement\" or \"Low Engagement\"\n",
    "#### Use KNN Regressor: \n",
    "- if you're predicting actual number of likes (e.g., 1,530 likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f62bf-d023-481c-b4e4-a1f955d45d02",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc3a98-bd2b-4e7e-aabb-fef696e0ce6f",
   "metadata": {},
   "source": [
    "## Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bbbd99-7f5f-4363-8a84-f9e65a5927e4",
   "metadata": {},
   "source": [
    "- ‚úÖ Simple & Intuitive\n",
    "- Easy to understand, implement, and explain‚Äîgreat for teaching & prototyping\n",
    "- ‚úÖ No Training Phase\n",
    "- Stores the data and makes predictions on the fly (lazy learning)\n",
    "- ‚úÖ Flexible with Distance Metrics\n",
    "- You can customize how ‚Äúcloseness‚Äù is measured (Euclidean, Manhattan, etc.)\n",
    "- ‚úÖ Effective with Well-Separated Data\n",
    "- If classes or outputs are clearly spaced, KNN does a solid job\n",
    "- ‚úÖ Works on Non-linear Data\n",
    "- Doesn‚Äôt assume a model shape; adapts to data distribution naturally\n",
    "\n",
    "\n",
    "- ‚ùå Slow Prediction Time\n",
    "- Every new input requires scanning the whole dataset\tüëâ Use KDTree or BallTree structures for faster neighbor search\n",
    "- ‚ùå Sensitive to Irrelevant Features\n",
    "- Extra/noisy features distort distance calculations\tüëâ Apply feature selection or dimensionality reduction (e.g., PCA)\n",
    "- ‚ùå Needs Good Feature Scaling\n",
    "- Features with different scales skew distances\tüëâ Normalize or standardize data (StandardScaler, MinMaxScaler)\n",
    "- ‚ùå Poor with High-Dimensional Data\n",
    "- Curse of dimensionality kicks in\tüëâ Use PCA or t-SNE to reduce dimensionality while preserving structure\n",
    "- ‚ùå Struggles with Imbalanced Classes\n",
    "- Majority class dominates predictions\tüëâ Try oversampling, SMOTE, or weighted voting (weights=\"distance\")\n",
    "- ‚ùå Memory Intensive\n",
    "- Stores entire training dataset\tüëâ Use data compression or switch to models with learned parameters if scalability is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa339e7-934e-46c9-be5d-636fc58b6afd",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109197c-c891-4499-9b0a-bd1ab1c85575",
   "metadata": {},
   "source": [
    "## Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcd3ad4-dda7-4a6e-8ff6-4f901cfe8486",
   "metadata": {},
   "source": [
    "### Path Style\t\n",
    "#### Euclidien\n",
    "- Straight-line (‚Äúas the crow flies‚Äù)\t\n",
    "#### Manhattan \n",
    "- Grid-based (‚Äúlike walking city blocks‚Äù)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124b6a3-12ed-4918-bb6a-a1ce19d87f3f",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244024e7-b8fe-4edb-af22-4b6a37a48452",
   "metadata": {},
   "source": [
    "## Q10. What is the role of feature scaling in KNN?\n",
    "## Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460e8ba-8417-400f-8c54-eae541038d09",
   "metadata": {},
   "source": [
    "#### KNN uses distance metrics (like Euclidean or Manhattan) to find neighbors. But if features have very different scales:\n",
    "- Features with larger numerical ranges dominate the distance calculation\n",
    "- This leads to biased neighbors and poor predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca817f-02a6-42ba-9ede-f117320d746e",
   "metadata": {},
   "source": [
    "#### Techniques for Scaling\n",
    "### 1. Min-Max Scaling (Normalization)\n",
    "- Scales data to [0, 1] range.\n",
    "### 2. Standardization (Z-score Scaling)\n",
    "- Centers features around mean 0 with standard deviation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
